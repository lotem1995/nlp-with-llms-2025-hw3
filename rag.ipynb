{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7aae3a9",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "Implement a base RAG module in DSPy. \n",
    "Given a question, retrieve the top-k documents in a list of HTML documents, then pass them as context to an LLM.\n",
    "\n",
    "Refer to https://dspy.ai/tutorials/rag/. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edec48e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dspy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load an extremely efficient local model for retrieval\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dspy'"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load an extremely efficient local model for retrieval\n",
    "model = SentenceTransformer(\"sentence-transformers/static-retrieval-mrl-en-v1\", device=\"gpu\")\n",
    "\n",
    "# Create an embedder using the model's encode method\n",
    "embedder = dspy.Embedder(model.encode)\n",
    "\n",
    "# Traverse a directory and read html files - extract text from the html files\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "def read_html_files(directory):\n",
    "    texts = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".html\"):\n",
    "            with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "                soup = BeautifulSoup(file, 'html.parser')\n",
    "                texts.append(soup.get_text())\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f634c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = read_html_files(\"../PragmatiCQA-sources/The Legend of Zelda\")\n",
    "print(f\"Loaded {len(corpus)} documents. Will encode them below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0051d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the retriever\n",
    "max_characters = 10000  # for truncating >99th percentile of documents\n",
    "topk_docs_to_retrieve = 5  # number of documents to retrieve per search query\n",
    "\n",
    "search = dspy.retrievers.Embeddings(embedder=embedder, corpus=corpus, k=topk_docs_to_retrieve)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b129af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm = dspy.LM('ollama_chat/devstral', api_base='http://localhost:11434', api_key='')\n",
    "lm = dspy.LM('xai/grok-3-mini')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.respond = dspy.ChainOfThought('context, question -> response')\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = search(question).passages\n",
    "        return self.respond(context=context, question=question)\n",
    "    \n",
    "rag = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499af707",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag(question=\"What is the main plot of The Legend of Zelda?\")  # Example query\n",
    "\n",
    "print(answer.response)  # Print the response from the RAG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e19c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'What year did the Legend of Zelda come out?' \n",
    "\n",
    "print(rag(question=q).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45c579",
   "metadata": {},
   "source": [
    "Part 4.3 â€” Traditional QA baseline (start)\n",
    "\n",
    "Plan:\n",
    "- Use the existing retriever `search` to obtain retrieved passages for a question.\n",
    "- Use Hugging Face's 'distilbert-base-cased-distilled-squad' extractive QA pipeline to answer the question given:\n",
    "  1) Literal spans (from dataset),\n",
    "  2) Pragmatic spans (from dataset),\n",
    "  3) Retrieved context (from `search`).\n",
    "- Evaluate these three configurations with dspy.evaluate.SemanticF1 on the first question of each conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e91a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads validation data, builds HF QA pipeline, runs example predictions and computes SemanticF1.\n",
    "from transformers import pipeline\n",
    "import json, os\n",
    "import dspy\n",
    "from dspy.evaluate import SemanticF1\n",
    "\n",
    "# Helper to load jsonl (repeat if not already present in this notebook)\n",
    "def read_data(filename, dataset_dir=\"../PragmatiCQA/data\"):\n",
    "    corpus = []\n",
    "    with open(os.path.join(dataset_dir, filename), 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            corpus.append(json.loads(line))\n",
    "    return corpus\n",
    "\n",
    "# Load validation set (first-question evaluation)\n",
    "val = read_data(\"val.jsonl\")\n",
    "\n",
    "# Build a simple extractive QA pipeline (CPU). Change device if you have GPU.\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"distilbert/distilbert-base-cased-distilled-squad\",\n",
    "    tokenizer=\"distilbert/distilbert-base-cased-distilled-squad\",\n",
    ")\n",
    "\n",
    "# SemanticF1 judge\n",
    "metric = SemanticF1(decompositional=True)\n",
    "\n",
    "def run_traditional_qa_on_first_question(example, search, qa_pipeline, metric):\n",
    "    # example is one document from PragmatiCQA (topic + 'qas' list)\n",
    "    if not example.get(\"qas\"):\n",
    "        return None\n",
    "    qa = example[\"qas\"][0]\n",
    "    question = qa[\"q\"]\n",
    "    gold = qa[\"a\"]\n",
    "\n",
    "    # assemble contexts\n",
    "    literal_spans = [s[\"text\"] for s in qa[\"a_meta\"].get(\"literal_obj\", [])]\n",
    "    pragmatic_spans = [s[\"text\"] for s in qa[\"a_meta\"].get(\"pragmatic_obj\", [])]\n",
    "    literal_context = \" \".join(literal_spans).strip()\n",
    "    pragmatic_context = \" \".join(pragmatic_spans).strip()\n",
    "\n",
    "    # retrieved context using the notebook's retriever 'search'\n",
    "    retrieved_passages = search(question).passages\n",
    "    retrieved_context = \" \".join(retrieved_passages).strip()\n",
    "\n",
    "    def answer_from_context(q, ctx):\n",
    "        if not ctx:\n",
    "            return \"\"\n",
    "        out = qa_pipeline(question=q, context=ctx)\n",
    "        # pipeline returns dict with 'answer'\n",
    "        return out.get(\"answer\", \"\") if isinstance(out, dict) else (out[0].get(\"answer\",\"\") if out else \"\")\n",
    "\n",
    "    pred_literal = answer_from_context(question, literal_context)\n",
    "    pred_pragmatic = answer_from_context(question, pragmatic_context)\n",
    "    pred_retrieved = answer_from_context(question, retrieved_context)\n",
    "\n",
    "    # Prepare dspy.Example for evaluation (use retrieved_context as input context)\n",
    "    gold_ex = dspy.Example(question=question, response=gold, inputs={\"context\": retrieved_context})\n",
    "    lit_ex = dspy.Example(question=question, response=pred_literal, inputs={\"context\": retrieved_context})\n",
    "    prag_ex = dspy.Example(question=question, response=pred_pragmatic, inputs={\"context\": retrieved_context})\n",
    "    retr_ex = dspy.Example(question=question, response=pred_retrieved, inputs={\"context\": retrieved_context})\n",
    "\n",
    "    scores = {\n",
    "        \"literal\": metric(gold_ex, lit_ex),\n",
    "        \"pragmatic\": metric(gold_ex, prag_ex),\n",
    "        \"retrieved\": metric(gold_ex, retr_ex),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"gold\": gold,\n",
    "        \"pred_literal\": pred_literal,\n",
    "        \"pred_pragmatic\": pred_pragmatic,\n",
    "        \"pred_retrieved\": pred_retrieved,\n",
    "        \"scores\": scores\n",
    "    }\n",
    "\n",
    "# Quick smoke-run on the first 10 validation documents (or fewer)\n",
    "results = []\n",
    "for i, doc in enumerate(val[:10]):\n",
    "    res = run_traditional_qa_on_first_question(doc, search, qa_pipeline, metric)\n",
    "    if res:\n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(\"Q:\", res[\"question\"])\n",
    "        print(\"Gold (truncated):\", (res[\"gold\"][:200] + \"...\") if len(res[\"gold\"])>200 else res[\"gold\"])\n",
    "        print(\"Pred (literal):\", res[\"pred_literal\"])\n",
    "        print(\"Pred (pragmatic):\", res[\"pred_pragmatic\"])\n",
    "        print(\"Pred (retrieved):\", res[\"pred_retrieved\"])\n",
    "        print(\"Scores:\", res[\"scores\"])\n",
    "        print(\"-\"*80)\n",
    "        results.append(res[\"scores\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-with-llms-2025-hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
